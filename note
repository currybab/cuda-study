# 함수 실행 공간 지정 키워드
- __host__ : host에서 호출, host에서 실행
- __device__ : device에서 호출, device에서 실행
- __global__ : host에서 호출되지만 device에서 실행

# 디바이스 메모리 할당
cudaError_t cudaMalloc(void ** ptr, size_t size);

# 디바이스 메모리 해제
cudaError_t cudaFree(void * ptr);

# 디바이스 메모리 초기화
cudaError_t cudaMemset(void * ptr, int value, size_t size);

# 에러 코드 확인
__host__ __device__ const char* cudaGetErrorName (cudaError_t error);

# 디바이스 메모리 사용량 확인
cudaError_t cudaMemGetInfo(size_t * free, size_t * total);

# 장치간 데이터 복사
cudaError_t cudaMemcpy(void * dst, const void * src, size_t size, enum cudaMemcpyKind kind);

- cudaMemcpyHostToHost: 호스트 메모리 -> 호스트 메모리
- cudaMemcpyHostToDevice: 호스트 메모리 -> 디바이스 메모리
- cudaMemcpyDeviceToHost: 디바이스 메모리 -> 호스트 메모리
- cudaMemcpyDeviceToDevice: 디바이스 메모리 -> 디바이스 메모리
- cudaMemcpyDefault: dst와 src의 포인터 값에 의해 결정 (unified virtual addressing을 지원하는 시스템에서만 사용 가능)

- 2차원, 3차원 데이터 복사를 돕는 cudaMemcpy2D(), cudaMemcpy3D()
- 비동기 복사를 돕는 cudaMemcpyAsync(), cudaMemcpy2DAsync(), cudaMemcpy3DAsync()

# 커널 함수 호출 동기화
cudaError_t cudaDeviceSynchronize();

# 스레드 레이아웃
- 워프 : 32개의 스레드
- 블록이 가지는 최대 스레드 수 : 1024

# gpu 정보 확인
cudaError_t cudaGetDeviceProperties(cudaDeviceProp* prop, int deviceID)
- name : GPU 이름
- major : GPU의 메이저 버전
- minor : GPU의 마이너 버전
- multiProcessorCount : GPU의 멀티 프로세서(SM) 수
- totalGlobalMem : GPU의 총 메모리 크기

# 시스템 내부 gpu의 개수
cudaError_t cudaGetDeviceCount(int * count)

# SM당 CUDA 코어의 갯수
int _ConvertSMVer2Cores(int major, int minor)
